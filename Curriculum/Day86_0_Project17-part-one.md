# <center> Project 17, part 1

When Apple introduced the iPhone X they ditched something that had been present since the earliest days of the iPhone: the home button. That simple piece of hardware had been there since the original launch as a way to help users get back to the home screen regardless of what they were doing and what app they were using – it made the whole device much less scary.

But as we became accustomed to working with increasingly large panes of glass, Apple started to rely more heavily on gestures: we gained gesture recognizers, the ability to swipe to terminate apps, pull down and pull up menus for system features, and more.

But with iPhone X Apple really took things to the next level, because without the home button *almost* everything became a gesture. Apple even gave a talk at WWDC18 to encourage developers to think more about gestures, and there Chan Karunamuni from Apple’s human interface design team said something really important about gestures: “when it's feeling really good, sometimes people even say it feels natural, or magical.”

Do you want to build apps that feel natural? Of course you do. This new app we’re building is going to rely heavily on gestures, and after only a few seconds of using it you’ll be using the gestures at light speed. That’s exactly what we’re aiming for: gestures that feel so natural that you struggle to imagine them working any other way.

**Today you have four topics to work through, in which you’ll learn about gestures, haptics, hit testing, and more.**

- Flashzilla: Introduction
- How to use gestures in SwiftUI
- Making vibrations with UINotificationFeedbackGenerator and Core Haptics
- Disabling user interactivity with allowsHitTesting()